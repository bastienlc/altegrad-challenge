{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "from scipy.optimize import minimize\n",
                "from sklearn.metrics import label_ranking_average_precision_score\n",
                "from transformers import AutoTokenizer\n",
                "\n",
                "from ensembling.embeddings import compute_embeddings\n",
                "from ensembling.fuse import (\n",
                "    condorcet_fuse,\n",
                "    identity_norm,\n",
                "    max_norm,\n",
                "    mean_fuse,\n",
                "    min_max_norm,\n",
                "    prod_fuse,\n",
                "    rank_norm,\n",
                "    reciprocal_rank_fuse,\n",
                "    strange_norm,\n",
                "    sum_norm,\n",
                "    zmuv_norm,\n",
                ")\n",
                "from ensembling.similarities import compute_similarities, load_similarities\n",
                "from metrics import Metrics\n",
                "from models import DiffPoolModel, GATModel\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "np.set_printoptions(precision=4, linewidth=200)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define the models in the ensemble"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define the different models in the ensemble\n",
                "\n",
                "models = [\n",
                "    DiffPoolModel(  # diffpool-base\n",
                "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "        num_node_features=300,\n",
                "        nout=384,\n",
                "    ),\n",
                "    DiffPoolModel(  # diffpool-big\n",
                "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "        num_node_features=300,\n",
                "        nout=384,\n",
                "        d_pooling_layers=[30, 10, 3, 1],\n",
                "        d_encoder_hidden_dims=[300, 600, 1200, 1200],\n",
                "        d_encoder_linear_layers=[[300], [600], [1200, 600], [1200, 600]],\n",
                "        d_encoder_num_heads=[3, 6, 12, 12],\n",
                "        d_encoder_num_layers=[10, 5, 3, 1],\n",
                "        d_linear=1200,\n",
                "        dropout=0,\n",
                "    ),\n",
                "    DiffPoolModel(  # diffpool-linear\n",
                "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "        num_node_features=300,\n",
                "        nout=384,\n",
                "        d_pooling_layers=[15, 5, 1],\n",
                "        d_encoder_hidden_dims=[600, 600, 600],\n",
                "        d_encoder_linear_layers=[[300, 300], [300, 300], [300, 300]],\n",
                "        d_encoder_num_heads=[3, 3, 3],\n",
                "        d_encoder_num_layers=[4, 3, 2],\n",
                "        d_linear=1200,\n",
                "        dropout=0,\n",
                "    ),\n",
                "    DiffPoolModel(  # diffpool-shallow\n",
                "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "        num_node_features=300,\n",
                "        nout=384,\n",
                "        d_pooling_layers=[20, 3],\n",
                "        d_encoder_hidden_dims=[1200, 1200],\n",
                "        d_encoder_linear_layers=[[150, 150, 150, 150], [150, 150, 150, 150]],\n",
                "        d_encoder_num_heads=[5, 5],\n",
                "        d_encoder_num_layers=[4, 3],\n",
                "        d_linear=2000,\n",
                "        dropout=0,\n",
                "    ),\n",
                "    DiffPoolModel(  # diffpool-deep\n",
                "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "        num_node_features=300,\n",
                "        nout=384,\n",
                "        d_pooling_layers=[15, 10, 5, 1],\n",
                "        d_encoder_hidden_dims=[600, 600, 600, 600],\n",
                "        d_encoder_linear_layers=[\n",
                "            [150, 150, 150],\n",
                "            [150, 150, 150],\n",
                "            [150, 150, 150],\n",
                "            [150, 150, 150],\n",
                "        ],\n",
                "        d_encoder_num_heads=[3, 3, 3, 3],\n",
                "        d_encoder_num_layers=[4, 3, 2, 2],\n",
                "        d_linear=700,\n",
                "        dropout=0,\n",
                "    ),\n",
                "    GATModel(  # gat\n",
                "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "        num_node_features=300,\n",
                "        nout=384,\n",
                "        d_hidden_dim=1200,\n",
                "        num_layers=3,\n",
                "        num_heads=6,\n",
                "        d_linear_layers=[\n",
                "            1200,\n",
                "            600,\n",
                "        ],\n",
                "        dropout=0,\n",
                "        activation=\"LeakyReLU\",\n",
                "    ),\n",
                "    DiffPoolModel(  # diffpool-large\n",
                "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "        num_node_features=300,\n",
                "        nout=384,\n",
                "        d_pooling_layers=[15, 5, 1],\n",
                "        d_encoder_hidden_dims=[1200, 1200, 1200],\n",
                "        d_encoder_linear_layers=[[1200, 600], [1200, 600], [1200, 600]],\n",
                "        d_encoder_num_heads=[6, 6, 6],\n",
                "        d_encoder_num_layers=[5, 3, 2],\n",
                "        d_linear=1200,\n",
                "        dropout=0.01,\n",
                "    ),\n",
                "    DiffPoolModel(  # diffpool-medium\n",
                "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "        num_node_features=300,\n",
                "        nout=384,\n",
                "        d_pooling_layers=[15, 5, 1],\n",
                "        d_encoder_hidden_dims=[600, 600, 600],\n",
                "        d_encoder_linear_layers=[[600, 300], [600, 300], [600, 300]],\n",
                "        d_encoder_num_heads=[6, 6, 6],\n",
                "        d_encoder_num_layers=[6, 4, 3],\n",
                "        d_linear=1200,\n",
                "        dropout=0.01,\n",
                "    ),\n",
                "]\n",
                "\n",
                "tokenizers = [\n",
                "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
                "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
                "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
                "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
                "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
                "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
                "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
                "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
                "]\n",
                "\n",
                "saved_paths = [\n",
                "    \"./outputs/diffpool-base/model99.pt\",\n",
                "    \"./outputs/diffpool-big/model99.pt\",\n",
                "    \"./outputs/diffpool-linear/model99.pt\",\n",
                "    \"./outputs/diffpool-shallow/model99.pt\",\n",
                "    \"./outputs/diffpool-deep/model99.pt\",\n",
                "    \"./outputs/gat/model99.pt\",\n",
                "    \"./outputs/diffpool-large/model99.pt\",\n",
                "    \"./outputs/diffpool-medium/model99.pt\",\n",
                "]\n",
                "\n",
                "metrics = [\n",
                "    Metrics(loss=\"circle\"),\n",
                "    Metrics(loss=\"circle\"),\n",
                "    Metrics(loss=\"circle\"),\n",
                "    Metrics(loss=\"circle\"),\n",
                "    Metrics(loss=\"circle\"),\n",
                "    Metrics(loss=\"circle\"),\n",
                "    Metrics(loss=\"circle\"),\n",
                "    Metrics(loss=\"circle\"),\n",
                "]\n",
                "\n",
                "skip = [\n",
                "    False,\n",
                "    False,\n",
                "    False,\n",
                "    False,\n",
                "    False,\n",
                "    False,\n",
                "    False,\n",
                "    False,\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Which models do we actually use ?\n",
                "models_indices = [0, 1, 2, 3, 4, 5, 6, 7]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Precompute all the similarities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for split in [\"val\", \"test\"]:\n",
                "    compute_embeddings(\n",
                "        models,\n",
                "        tokenizers,\n",
                "        saved_paths,\n",
                "        skip,\n",
                "        split,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for split in [\"val\", \"test\"]:\n",
                "    compute_similarities(metrics, skip, split)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validation score for each model\n",
                "for k in models_indices:\n",
                "    val_similarities = torch.load(f\"./outputs/similarities/val/similarity{k}.pt\")\n",
                "    labels = np.eye(val_similarities.shape[1])\n",
                "    print(k, label_ranking_average_precision_score(labels, val_similarities))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Grid search for a good intialization of the weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generating grid\n",
                "grid = np.meshgrid(*[[0, 1, 2] for _ in range(len(models_indices))])\n",
                "grid = np.array([g.flatten() for g in grid]).T\n",
                "grid = grid[1:]\n",
                "np.random.shuffle(grid)\n",
                "\n",
                "# Precompute to speed up\n",
                "val_similarities = load_similarities(\"val\", models_indices)\n",
                "val_similarities = strange_norm(val_similarities)\n",
                "labels = np.eye(val_similarities.shape[1])\n",
                "\n",
                "grid_weights = None\n",
                "best_score = 0\n",
                "iter = 0\n",
                "try:\n",
                "    for weights in grid:\n",
                "        iter += 1\n",
                "        val_aggregation = np.average(val_similarities, axis=0, weights=weights)\n",
                "        score = label_ranking_average_precision_score(labels, val_aggregation)\n",
                "        if score > best_score:\n",
                "            print(\n",
                "                f\"Iteration {iter} | New best score {score} with weights {weights}\",\n",
                "                end=\"\\r\",\n",
                "            )\n",
                "            best_score = score\n",
                "            grid_weights = weights\n",
                "except KeyboardInterrupt:\n",
                "    pass\n",
                "\n",
                "with open(\"./outputs/weights\", \"a\") as f:\n",
                "    f.write(\n",
                "        f\"{str(grid_weights)} | {label_ranking_average_precision_score(labels, mean_fuse(val_similarities, weights=grid_weights, norm=identity_norm))}\\n\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Simple method to optimize the weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "val_similarities = load_similarities(\"val\", models_indices)\n",
                "val_similarities = strange_norm(val_similarities)\n",
                "labels = np.eye(val_similarities.shape[1])\n",
                "\n",
                "\n",
                "def objective(weights):\n",
                "    val_aggregation = np.average(val_similarities, axis=0, weights=weights)\n",
                "    score = label_ranking_average_precision_score(labels, val_aggregation)\n",
                "    print(f\"{score:.5f} | \", weights, end=\"\\r\")\n",
                "    return -score\n",
                "\n",
                "\n",
                "res = minimize(\n",
                "    objective,\n",
                "    np.array([grid_weights]),\n",
                "    method=\"Powell\",\n",
                "    tol=1e-4,\n",
                ")\n",
                "weights = res.x\n",
                "\n",
                "# Store the weights for later reference\n",
                "with open(\"./outputs/weights\", \"a\") as f:\n",
                "    f.write(\n",
                "        f\"{str(weights)} | {label_ranking_average_precision_score(labels, mean_fuse(val_similarities, weights=weights, norm=identity_norm))}\\n\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Results with different fusing methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "val_similarities = load_similarities(\"val\", models_indices)\n",
                "labels = np.eye(val_similarities.shape[1])\n",
                "\n",
                "for fuse in [mean_fuse, prod_fuse, reciprocal_rank_fuse, condorcet_fuse]:\n",
                "    for norm in [rank_norm, strange_norm, min_max_norm, sum_norm, max_norm, zmuv_norm]:\n",
                "        score = label_ranking_average_precision_score(\n",
                "            labels, fuse(val_similarities, weights=weights, norm=norm)\n",
                "        )\n",
                "        print(f\"{fuse.__name__} | {norm.__name__} || {score:.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Final test results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "val_similarities = load_similarities(\"val\", models_indices)\n",
                "labels = np.eye(val_similarities.shape[1])\n",
                "print(\n",
                "    label_ranking_average_precision_score(\n",
                "        labels, mean_fuse(val_similarities, weights=weights)\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_similarities = load_similarities(\"test\", models_indices)\n",
                "test_aggregation = mean_fuse(test_similarities, weights=weights)\n",
                "\n",
                "solution = pd.DataFrame(test_aggregation)\n",
                "solution[\"ID\"] = solution.index\n",
                "solution = solution[[\"ID\"] + [col for col in solution.columns if col != \"ID\"]]\n",
                "solution.to_csv(\"outputs/ensemble_solution.csv\", index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "altegrad",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
