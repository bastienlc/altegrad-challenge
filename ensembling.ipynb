{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from models.diffpool import DiffPoolModel\n",
    "from models.diffpool.old import DiffPoolModel as OldDiffpoolModel\n",
    "from metrics import Metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ensembling.embeddings import compute_embeddings\n",
    "from ensembling.similarities import compute_similarities, load_similarities\n",
    "from ensembling.fuse import mean_fuse, condorcet_fuse, reciprocal_rank_fuse\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the models in the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the different models in the ensemble\n",
    "\n",
    "models = [\n",
    "    DiffPoolModel(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        num_node_features=300,\n",
    "        nout=384,\n",
    "    ),\n",
    "    DiffPoolModel(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "        num_node_features=300,\n",
    "        nout=768,\n",
    "    ),\n",
    "    DiffPoolModel(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        num_node_features=300,\n",
    "        nout=384,\n",
    "        d_pooling_layers=[30, 10, 3, 1],\n",
    "        d_encoder_hidden_dims=[300, 600, 1200, 1200],\n",
    "        d_encoder_linear_layers=[[300], [600], [1200, 600], [1200, 600]],\n",
    "        d_encoder_num_heads=[3, 6, 12, 12],\n",
    "        d_encoder_num_layers=[10, 5, 3, 1],\n",
    "        d_linear=1200,\n",
    "        dropout=0,\n",
    "    ),\n",
    "    DiffPoolModel(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        num_node_features=300,\n",
    "        nout=384,\n",
    "    ),\n",
    "    DiffPoolModel(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        num_node_features=300,\n",
    "        nout=384,\n",
    "    ),\n",
    "    OldDiffpoolModel(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        num_node_features=300,\n",
    "        nout=384,\n",
    "    ),\n",
    "    DiffPoolModel(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        num_node_features=300,\n",
    "        nout=384,\n",
    "        d_pooling_layers=[15, 5, 1],\n",
    "        d_encoder_hidden_dims=[600, 600, 600],\n",
    "        d_encoder_linear_layers=[[300, 300], [300, 300], [300, 300]],\n",
    "        d_encoder_num_heads=[3, 3, 3],\n",
    "        d_encoder_num_layers=[4, 3, 2],\n",
    "        d_linear=1200,\n",
    "        dropout=0,\n",
    "    ),\n",
    "    DiffPoolModel(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        num_node_features=300,\n",
    "        nout=384,\n",
    "        d_pooling_layers=[15, 5, 1],\n",
    "        d_encoder_hidden_dims=[600, 600, 600],\n",
    "        d_encoder_linear_layers=[[300, 300], [300, 300], [300, 300]],\n",
    "        d_encoder_num_heads=[3, 3, 3],\n",
    "        d_encoder_num_layers=[4, 3, 2],\n",
    "        d_linear=1200,\n",
    "        dropout=0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "tokenizers = [\n",
    "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\"),\n",
    "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "]\n",
    "\n",
    "saved_paths = [\n",
    "    \"./outputs/saved/circle_loss/circle70.pt\",\n",
    "    \"./outputs/saved/mpnet/model60.pt\",\n",
    "    \"./outputs/saved/diffpool30M/model63.pt\",\n",
    "    \"./outputs/saved/best-diffpool-kaggle/model204.pt\",\n",
    "    \"./outputs/saved/sofiane/NADAM 0.82/model24.pt\",\n",
    "    \"./outputs/saved/sofiane/First diffpool 0.845/model35.pt\",\n",
    "    \"./outputs/saved/diffpool87/model54.pt\",\n",
    "    \"./outputs/saved/diffpool87other/model70.pt\",\n",
    "]\n",
    "\n",
    "metrics = [\n",
    "    Metrics(loss=\"circle\"),\n",
    "    Metrics(loss=\"circle\"),\n",
    "    Metrics(loss=\"circle\"),\n",
    "    Metrics(loss=\"circle\"),\n",
    "    Metrics(loss=\"circle\"),\n",
    "    Metrics(loss=\"circle\"),\n",
    "    Metrics(loss=\"circle\"),\n",
    "    Metrics(loss=\"circle\"),\n",
    "]\n",
    "\n",
    "skip = [True, True, True, True, True, True, True, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which models do we actually use ?\n",
    "models_indices = [0, 1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute all the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"val\", \"test\"]:\n",
    "    print(split)\n",
    "    compute_embeddings(\n",
    "        models,\n",
    "        tokenizers,\n",
    "        saved_paths,\n",
    "        skip,\n",
    "        split,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"val\", \"test\"]:\n",
    "    print(split)\n",
    "    compute_similarities(metrics, skip, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best weights on validation data using simple method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_similarities = load_similarities(\"val\", models_indices)\n",
    "\n",
    "val_similarities = (val_similarities - val_similarities.min(axis=1)[:, None, :]) / (\n",
    "    val_similarities.max(axis=1)[:, None, :] - val_similarities.min(axis=1)[:, None, :]\n",
    ")\n",
    "labels = np.eye(val_similarities.shape[1])\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "\n",
    "def objective(weights):\n",
    "    val_aggregation = np.average(val_similarities, axis=0, weights=weights)\n",
    "    score = label_ranking_average_precision_score(labels, val_aggregation)\n",
    "    print(f\"{score:.4f} | \", weights, end=\"\\r\")\n",
    "    return -score\n",
    "\n",
    "\n",
    "res = minimize(\n",
    "    objective, np.random.normal(10, 3, len(models_indices)), method=\"Nelder-Mead\"\n",
    ")\n",
    "weights = res.x\n",
    "\n",
    "# Store the weights for later reference\n",
    "with open(\"./outputs/weights\", \"a\") as f:\n",
    "    f.write(\n",
    "        f\"{str(weights)} | {label_ranking_average_precision_score(labels, mean_fuse(val_similarities, weights))}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with different fusing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_similarities = load_similarities(\"val\", models_indices)\n",
    "val_aggregation = mean_fuse(val_similarities, weights)\n",
    "print(\n",
    "    \"Validation score :\",\n",
    "    label_ranking_average_precision_score(\n",
    "        np.eye(len(val_aggregation)), val_aggregation\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reciprocal rank fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_similarities = load_similarities(\"val\", models_indices)\n",
    "val_aggregation = reciprocal_rank_fuse(val_similarities, weights)\n",
    "print(\n",
    "    \"Validation score :\",\n",
    "    label_ranking_average_precision_score(\n",
    "        np.eye(len(val_aggregation)), val_aggregation\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condorcet fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_similarities = load_similarities(\"val\", models_indices)\n",
    "val_aggregation = condorcet_fuse(val_similarities, weights)\n",
    "print(\n",
    "    \"Validation score :\",\n",
    "    label_ranking_average_precision_score(\n",
    "        np.eye(len(val_aggregation)), val_aggregation\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_similarities = load_similarities(\"test\", models_indices)\n",
    "test_aggregation = mean_fuse(test_similarities, weights)\n",
    "\n",
    "solution = pd.DataFrame(test_aggregation)\n",
    "solution[\"ID\"] = solution.index\n",
    "solution = solution[[\"ID\"] + [col for col in solution.columns if col != \"ID\"]]\n",
    "solution.to_csv(\"outputs/ensemble_solution.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altegrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
