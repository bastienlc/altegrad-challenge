{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One sided learning\n",
    "\n",
    "In some cases we may want to train only the graph encoder with the initial text embeddings, because it may require a lot of iterations to get a good representation of the graphs. This way it will train much faster than if the text encoder is trained simultaneously. Obviously the overall performances will be lower, but we can then fine-tune the whole model. Hopefully this will allow us to get a better graph encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "import torch.nn as nn\n",
    "from utils import train\n",
    "from models.baseline import TextEncoder\n",
    "from models.gat.gat import GATEncoder\n",
    "from datasets import OneSidedDataset\n",
    "from models.gat import GATModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train only the graph encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings_dim = 384\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "text_encoder = TextEncoder(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataset with the text embeddings :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    text_encoder: nn.Module,\n",
    "    device: torch.device,\n",
    "    batch_size: int = 32,\n",
    "    root=\".\",\n",
    "    features=[],\n",
    "    shuffle=True,\n",
    "):\n",
    "    gt = np.load(f\"{root}/data/token_embedding_dict.npy\", allow_pickle=True)[()]\n",
    "    train_dataset = OneSidedDataset(\n",
    "        root=f\"{root}/data/\",\n",
    "        gt=gt,\n",
    "        split=\"train\",\n",
    "        tokenizer=tokenizer,\n",
    "        text_encoder=text_encoder,\n",
    "        device=device,\n",
    "        features=features,\n",
    "    )\n",
    "    val_dataset = OneSidedDataset(\n",
    "        root=f\"{root}/data/\",\n",
    "        gt=gt,\n",
    "        split=\"val\",\n",
    "        tokenizer=tokenizer,\n",
    "        text_encoder=text_encoder,\n",
    "        device=device,\n",
    "        features=features,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "train_loader, val_loader = load_dataset(tokenizer, text_encoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneSidedModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_encoder,\n",
    "    ):\n",
    "        super(OneSidedModel, self).__init__()\n",
    "        self.graph_encoder = graph_encoder\n",
    "\n",
    "    def forward(self, graph_batch, input_ids, attention_mask):\n",
    "        graph_encoded = self.graph_encoder(graph_batch)\n",
    "        return graph_encoded, graph_batch.y\n",
    "\n",
    "    def get_text_encoder(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_graph_encoder(self):\n",
    "        return self.graph_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_encoder = GATEncoder(\n",
    "    300,\n",
    "    embeddings_dim,\n",
    ").to(device)\n",
    "\n",
    "model = OneSidedModel(graph_encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=5e-5, betas=(0.9, 0.999), weight_decay=0.01\n",
    ")\n",
    "\n",
    "save_path, _, _ = train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    nb_epochs=50,\n",
    "    device=device,\n",
    "    save_name=\"one_side\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish training the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = \"./outputs/one_side26.pt\"\n",
    "save_path = \"./outputs/one_side26_full.pt\"\n",
    "\n",
    "checkpoint = torch.load(load_from)\n",
    "\n",
    "full_model = GATModel(\n",
    "    model_name=model_name,\n",
    "    num_node_features=300,\n",
    "    nout=embeddings_dim,\n",
    ").to(device)\n",
    "\n",
    "# change keys of checkpoint to remove 'graph_encoder.' prefix\n",
    "new_state_dict = {}\n",
    "for k, v in checkpoint[\"model_state_dict\"].items():\n",
    "    if k.startswith(\"graph_encoder.\"):\n",
    "        name = k[14:]  # remove 'graph_encoder.' prefix\n",
    "        new_state_dict[name] = v\n",
    "    else:\n",
    "        new_state_dict[k] = v\n",
    "\n",
    "full_model.graph_encoder.load_state_dict(new_state_dict)\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    full_model.parameters(), lr=5e-5, betas=(0.9, 0.999), weight_decay=0.01\n",
    ")\n",
    "\n",
    "# save this checkpoint\n",
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": checkpoint[\"epoch\"],\n",
    "        \"model_state_dict\": full_model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"val_loss\": checkpoint[\"val_loss\"],\n",
    "        \"val_score\": checkpoint[\"val_score\"],\n",
    "    },\n",
    "    save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path, _, _ = train(\n",
    "    full_model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    nb_epochs=50,\n",
    "    device=device,\n",
    "    load_from=save_path,\n",
    "    save_name=\"one_side_full\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altegrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
